{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca579ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066d6e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train = fetch_20newsgroups(subset ='train')\n",
    "news_test = fetch_20newsgroups(subset ='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa97bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "944c80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the NLTK stopwords and stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c240b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to clean the text data\n",
    "def clean(text):\n",
    "    \n",
    "    # Removing email headers\n",
    "    text = text.split('\\n\\n', 1)[-1]\n",
    "    \n",
    "    # Removing any leading or trailing white space\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Removing any quoted text\n",
    "    text = '\\n'.join([line for line in text.split('\\n') if not line.startswith('>')])\n",
    "    \n",
    "    # Removing any URLs\n",
    "    text = ' '.join([word for word in text.split() if not word.startswith('http')])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c6d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to preprocess the text data\n",
    "def preprocess(text):\n",
    "    \n",
    "    # Removing punctuation marks and converting to lowercase\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    \n",
    "    # Tokenizing the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Removing stop words and stem the remaining words\n",
    "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "    \n",
    "    # Joining the words back into a string\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a775903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and preprocessing the text data in the dataset\n",
    "preprocessed_train_data = []\n",
    "for text in news_train.data:\n",
    "    cleaned_text = clean(text)\n",
    "    preprocessed_text = preprocess(cleaned_text)\n",
    "    preprocessed_train_data.append(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ea41fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_test_data = []\n",
    "for text in news_test.data:\n",
    "    cleaned_text = clean(text)\n",
    "    preprocessed_text = preprocess(cleaned_text)\n",
    "    preprocessed_test_data.append(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04a34be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "tfidf_vectors_train = vectorizer.fit_transform(preprocessed_train_data)\n",
    "\n",
    "# Transform the test data\n",
    "tfidf_vectors_test = vectorizer.transform(preprocessed_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "232aa764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4239a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNB:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_docs, num_words = X.shape\n",
    "        self.classes = np.unique(y)\n",
    "        num_classes = len(self.classes)\n",
    "\n",
    "        # Calculate class priors\n",
    "        self.class_priors = np.zeros(num_classes, dtype=np.float64)\n",
    "        for i, c in enumerate(self.classes):\n",
    "            self.class_priors[i] = np.sum(y == c) / num_docs\n",
    "\n",
    "        # Calculate word frequencies and conditional probabilities\n",
    "        self.word_freqs = np.zeros((num_classes, num_words), dtype=np.int64)\n",
    "        for i, c in enumerate(self.classes):\n",
    "            X_c = X[y == c]\n",
    "            self.word_freqs[i, :] = np.sum(X_c, axis=0)\n",
    "        total_word_freqs = np.sum(self.word_freqs, axis=1, keepdims=True)\n",
    "        self.cond_probs = (self.word_freqs + self.alpha) / (total_word_freqs + self.alpha * num_words)\n",
    "\n",
    "    def predict(self, X):\n",
    "        log_probs = np.log(self.class_priors) + X @ np.log(self.cond_probs.T)\n",
    "        return self.classes[np.argmax(log_probs, axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75be2845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(tfidf_vectors_train, news_train.target)\n",
    "predictions = nb_classifier.predict(tfidf_vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89989dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6777748274030801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(news_test.target, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a0b30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
